# ETL com databricks
 Este é um projeto pessoal desenvolivdo com pyspark com o objetivo de realizar um processo simples de etl.

## Objetivo
 Mostrar na prática um processo de extração, transformação e carga. <br />
 Realizando tratamento dos dados e separando-os em suas camadas sendo elas: bronze, silver e gold. <br />
 Enriquecendo os dados para ser consumíveis por analistas de dados, <br />
 cientistas de dados, analistas de dados e etc. 
 com dados tratados poderão fazer suas respectivas análises com dados confiáveis e tratados. 

## Como usar
 Você precisa criar sua conta no databricks community, criar um cluster e importar os arquivos que estarei disponibilizando neste repositório. <br />

## Resultado 
 Feito todos os processos, os dados serão tratados conforme a execução das células dos códigos <br /> 
 com os códigos você poderá tirar suas conclusões e ideias conforme seu aprendizado.

## Estrutura de Pasta

A estrutura de pastas do projeto está organizada da seguinte maneira:


-   `Gold_ETL(dados ja prontos)`: notebook com dados ja tratados.
-   `README.md`: Documentação explicando o projeto, instruções de uso e informações gerais.
-   `Raw_ETL(dados brutos)`: notebook com os dados brutos.
-   `Silver_ETL(tratamento dos dados)`: notebook com os arquivos e códigos de tratamento de dados (etapa de transformação)

 

 
